{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Machine Learning Techniques Using Pipelines - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you'lll use a Dataset created by Otto group, which was also used in a [Kaggle competition](https://www.kaggle.com/c/otto-group-product-classification-challenge/data).\n",
    "\n",
    "The description of the data set is as follows:\n",
    "\n",
    "The Otto Group is one of the world’s biggest e-commerce companies, with subsidiaries in more than 20 countries, including Crate & Barrel (USA), Otto.de (Germany) and 3 Suisses (France). They are selling millions of products worldwide every day, with several thousand products being added to our product line.\n",
    "\n",
    "A consistent analysis of the performance of our products is crucial. However, due to their global infrastructure, many identical products get classified differently. Therefore, the quality of our product analysis depends heavily on the ability to accurately cluster similar products. The better the classification, the more insights Otto Group can generate about their product range.\n",
    "\n",
    "In this lab, you'll use a data set containing:\n",
    "- A column `id`, which is an anonymous id unique to a product\n",
    "- 93 columns `feat_1`, `feat_2`, ..., `feat_93`, which are the various features of a product\n",
    "- a column `target` - the class of a product\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "- Compare different classification techniques\n",
    "- Construct pipelines in scikit-learn\n",
    "- Use pipelines in combination with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data Science Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be following the data science workflow:\n",
    "\n",
    "1. Initial data inspection, exploratory data analysis, and cleaning\n",
    "2. Feature engineering and selection\n",
    "3. create a baseline model\n",
    "4. create a machine learning pipeline and compare results with the baseline model\n",
    "5. Interpret the model and draw conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Initial data inspection, exploratory data analysis, and cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is stored in \"otto_group.csv\".\n",
    "\n",
    "Things to do here:\n",
    "- Check for NAs\n",
    "- Check the distributions\n",
    "- Check how many inputs there are\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>feat_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n",
       "id                                                                           \n",
       "1        1       0       0       0       0       0       0       0       0   \n",
       "2        0       0       0       0       0       0       0       1       0   \n",
       "3        0       0       0       0       0       0       0       1       0   \n",
       "4        1       0       0       1       6       1       5       0       0   \n",
       "5        0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "    feat_10   ...     feat_85  feat_86  feat_87  feat_88  feat_89  feat_90  \\\n",
       "id            ...                                                            \n",
       "1         0   ...           1        0        0        0        0        0   \n",
       "2         0   ...           0        0        0        0        0        0   \n",
       "3         0   ...           0        0        0        0        0        0   \n",
       "4         1   ...           0        1        2        0        0        0   \n",
       "5         0   ...           1        0        0        0        0        1   \n",
       "\n",
       "    feat_91  feat_92  feat_93   target  \n",
       "id                                      \n",
       "1         0        0        0  Class_1  \n",
       "2         0        0        0  Class_1  \n",
       "3         0        0        0  Class_1  \n",
       "4         0        0        0  Class_1  \n",
       "5         0        0        0  Class_1  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('otto_group.csv', index_col='id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 61878 entries, 1 to 61878\n",
      "Data columns (total 94 columns):\n",
      "feat_1     61878 non-null int64\n",
      "feat_2     61878 non-null int64\n",
      "feat_3     61878 non-null int64\n",
      "feat_4     61878 non-null int64\n",
      "feat_5     61878 non-null int64\n",
      "feat_6     61878 non-null int64\n",
      "feat_7     61878 non-null int64\n",
      "feat_8     61878 non-null int64\n",
      "feat_9     61878 non-null int64\n",
      "feat_10    61878 non-null int64\n",
      "feat_11    61878 non-null int64\n",
      "feat_12    61878 non-null int64\n",
      "feat_13    61878 non-null int64\n",
      "feat_14    61878 non-null int64\n",
      "feat_15    61878 non-null int64\n",
      "feat_16    61878 non-null int64\n",
      "feat_17    61878 non-null int64\n",
      "feat_18    61878 non-null int64\n",
      "feat_19    61878 non-null int64\n",
      "feat_20    61878 non-null int64\n",
      "feat_21    61878 non-null int64\n",
      "feat_22    61878 non-null int64\n",
      "feat_23    61878 non-null int64\n",
      "feat_24    61878 non-null int64\n",
      "feat_25    61878 non-null int64\n",
      "feat_26    61878 non-null int64\n",
      "feat_27    61878 non-null int64\n",
      "feat_28    61878 non-null int64\n",
      "feat_29    61878 non-null int64\n",
      "feat_30    61878 non-null int64\n",
      "feat_31    61878 non-null int64\n",
      "feat_32    61878 non-null int64\n",
      "feat_33    61878 non-null int64\n",
      "feat_34    61878 non-null int64\n",
      "feat_35    61878 non-null int64\n",
      "feat_36    61878 non-null int64\n",
      "feat_37    61878 non-null int64\n",
      "feat_38    61878 non-null int64\n",
      "feat_39    61878 non-null int64\n",
      "feat_40    61878 non-null int64\n",
      "feat_41    61878 non-null int64\n",
      "feat_42    61878 non-null int64\n",
      "feat_43    61878 non-null int64\n",
      "feat_44    61878 non-null int64\n",
      "feat_45    61878 non-null int64\n",
      "feat_46    61878 non-null int64\n",
      "feat_47    61878 non-null int64\n",
      "feat_48    61878 non-null int64\n",
      "feat_49    61878 non-null int64\n",
      "feat_50    61878 non-null int64\n",
      "feat_51    61878 non-null int64\n",
      "feat_52    61878 non-null int64\n",
      "feat_53    61878 non-null int64\n",
      "feat_54    61878 non-null int64\n",
      "feat_55    61878 non-null int64\n",
      "feat_56    61878 non-null int64\n",
      "feat_57    61878 non-null int64\n",
      "feat_58    61878 non-null int64\n",
      "feat_59    61878 non-null int64\n",
      "feat_60    61878 non-null int64\n",
      "feat_61    61878 non-null int64\n",
      "feat_62    61878 non-null int64\n",
      "feat_63    61878 non-null int64\n",
      "feat_64    61878 non-null int64\n",
      "feat_65    61878 non-null int64\n",
      "feat_66    61878 non-null int64\n",
      "feat_67    61878 non-null int64\n",
      "feat_68    61878 non-null int64\n",
      "feat_69    61878 non-null int64\n",
      "feat_70    61878 non-null int64\n",
      "feat_71    61878 non-null int64\n",
      "feat_72    61878 non-null int64\n",
      "feat_73    61878 non-null int64\n",
      "feat_74    61878 non-null int64\n",
      "feat_75    61878 non-null int64\n",
      "feat_76    61878 non-null int64\n",
      "feat_77    61878 non-null int64\n",
      "feat_78    61878 non-null int64\n",
      "feat_79    61878 non-null int64\n",
      "feat_80    61878 non-null int64\n",
      "feat_81    61878 non-null int64\n",
      "feat_82    61878 non-null int64\n",
      "feat_83    61878 non-null int64\n",
      "feat_84    61878 non-null int64\n",
      "feat_85    61878 non-null int64\n",
      "feat_86    61878 non-null int64\n",
      "feat_87    61878 non-null int64\n",
      "feat_88    61878 non-null int64\n",
      "feat_89    61878 non-null int64\n",
      "feat_90    61878 non-null int64\n",
      "feat_91    61878 non-null int64\n",
      "feat_92    61878 non-null int64\n",
      "feat_93    61878 non-null int64\n",
      "target     61878 non-null object\n",
      "dtypes: int64(93), object(1)\n",
      "memory usage: 44.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/learn-env/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "color kwarg must have one color per data set. 93 data sets and 1 colors were provided",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-4283402f0901>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/seaborn/distributions.py\u001b[0m in \u001b[0;36mdistplot\u001b[0;34m(a, bins, hist, kde, rug, fit, hist_kws, kde_kws, rug_kws, fit_kws, color, vertical, norm_hist, axlabel, label, ax)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0mhist_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist_kws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"color\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         ax.hist(a, bins, orientation=orientation,\n\u001b[0;32m--> 225\u001b[0;31m                 color=hist_color, **hist_kws)\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhist_color\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mhist_kws\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"color\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist_color\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mhist\u001b[0;34m(self, x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, normed, **kwargs)\u001b[0m\n\u001b[1;32m   6563\u001b[0m                     \u001b[0;34m\"color kwarg must have one color per data set. %d data \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6564\u001b[0m                     \"sets and %d colors were provided\" % (nx, len(color)))\n\u001b[0;32m-> 6565\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6567\u001b[0m         \u001b[0;31m# If bins are not specified either explicitly or via range,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: color kwarg must have one color per data set. 93 data sets and 1 colors were provided"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at all the histograms, you can tell that a lot of the data are zero-inflated, so most of the variables contain mostly zeros and then some higher values here and there. No normality, but for most machine learning techniques this is not an issue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the data is zero-inflated the boxplots look as shown above. Because there are this many zeroes, most values above zero will seem to be outliers. The safe decision for this data is to not delete any outliers and see what happens. With many 0s, sparse data is available and high values may be super informative. More-over, without having any intuitive meaning for each of the features, we don't know if a value of ~260 is actually an outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering and selection with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the correlation structure of your features using a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use PCA to downscale your features. Use PCA to select a number of features in a way that you still keep 80% of your explained variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a train test split with a test size of 40%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a relatively big training set. Feel free to make it smaller (down to ~20%), but for an initial run you can try smaller training sets so the computation time is more manageable.\n",
    "\n",
    "For now, simply use the original data and not the principal components. We looked at the PC's first to get a sense of our correlation structure, and to see how we can downsize our data without losing too much information. In what's next, you'll make PCA part of the pipeline!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your baseline model *in a pipeline setting*. In the pipeline\n",
    "- Your first step will be to scale your features down to the number of features that ensure you keep just 80% of your explained variance (which we saw before)\n",
    "- Your second step will be the building a basic logistic regression model.\n",
    "\n",
    "Make sure to fit the model using the training set, and test the result by obtaining the accuracy using the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a pipeline consisting of a linear SVM, a simple Decision Tree and a simple Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the above, but now create three different pipelines:\n",
    "- One for a standard linear SCM\n",
    "- One for a default decision tree\n",
    "- One for a RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline with grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct 3 pipelines with grid search\n",
    "- one for support vector machines - make sure your grid isn't too big. You'll see it takes quite a while to fit SVMs with non-linear kernel functions!\n",
    "- one for random forests - try to have around 40 different models\n",
    "- one for the adaboost algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM pipeline with grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your grid search object along with `.cv_results` to get the full result overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest pipeline with grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "\n",
    "Note that this solution is only one of many options. The results in the Random Forest and Adaboost models show that there is a lot of improvement possible tuning the hyperparameters further, so make sure to explore this yourself!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "Great! You now got a lot of practice in. What algorithm would you choose and why?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
